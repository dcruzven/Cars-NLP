{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.tokenize import regexp_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import re\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, StandardScaler\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import roc_auc_score, plot_roc_curve, plot_precision_recall_curve\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing out different applications of nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notebook dedicated to find the best nlp model for the car reviews**\n",
    "- Trying out lemmantizing\n",
    "- Trying out stemming\n",
    "- Used tfidvectorizer and a countingvectorizer\n",
    "- See which model performed the best and keep it to use with the other model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('CleanData3bins.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = data.drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DriveTrain</th>\n",
       "      <th>Mileage</th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>PriceCategory</th>\n",
       "      <th>CleanReviews</th>\n",
       "      <th>Year</th>\n",
       "      <th>newSize</th>\n",
       "      <th>newCyl</th>\n",
       "      <th>newMake</th>\n",
       "      <th>mpg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FWD</td>\n",
       "      <td>53200.0</td>\n",
       "      <td>29000.0</td>\n",
       "      <td>Average</td>\n",
       "      <td>Virtually nothing has gone wrong with my 2020 ...</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4</td>\n",
       "      <td>Toyota</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RWD</td>\n",
       "      <td>22690.0</td>\n",
       "      <td>55975.0</td>\n",
       "      <td>Expensive</td>\n",
       "      <td>Stranded today. Could not get to work. Somethi...</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6</td>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FWD</td>\n",
       "      <td>17854.0</td>\n",
       "      <td>38900.0</td>\n",
       "      <td>Average</td>\n",
       "      <td>Excellent road car, quiet, stable, comfortable...</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>6</td>\n",
       "      <td>Other</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FWD</td>\n",
       "      <td>60907.0</td>\n",
       "      <td>22125.0</td>\n",
       "      <td>Cheap</td>\n",
       "      <td>PURCHASED FROM NYE TOYOTA, MY FIRST TACOMA. LO...</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4</td>\n",
       "      <td>Toyota</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FWD</td>\n",
       "      <td>41614.0</td>\n",
       "      <td>23946.0</td>\n",
       "      <td>Cheap</td>\n",
       "      <td>I’ve own a 2020 Altima (under 30k miles) for a...</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>4</td>\n",
       "      <td>Nissan</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8469</th>\n",
       "      <td>FWD</td>\n",
       "      <td>78378.0</td>\n",
       "      <td>25500.0</td>\n",
       "      <td>Cheap</td>\n",
       "      <td>Only had the X5 for 4 weeks now but so far it ...</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>6</td>\n",
       "      <td>BMW</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8470</th>\n",
       "      <td>AWD</td>\n",
       "      <td>30909.0</td>\n",
       "      <td>35590.0</td>\n",
       "      <td>Average</td>\n",
       "      <td>When I bought my 2020 Tacoma V6 (3.5L) 4x4 in ...</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>6</td>\n",
       "      <td>Toyota</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8471</th>\n",
       "      <td>FWD</td>\n",
       "      <td>30186.0</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>Cheap</td>\n",
       "      <td>Everything is great except the rear view camer...</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4</td>\n",
       "      <td>INFINITI</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8472</th>\n",
       "      <td>FWD</td>\n",
       "      <td>22309.0</td>\n",
       "      <td>71077.0</td>\n",
       "      <td>Expensive</td>\n",
       "      <td>I have owned smaller SUV\\s and Trucks for over...</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>5.7</td>\n",
       "      <td>8</td>\n",
       "      <td>Toyota</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8473</th>\n",
       "      <td>FWD</td>\n",
       "      <td>9399.0</td>\n",
       "      <td>34988.0</td>\n",
       "      <td>Average</td>\n",
       "      <td>Transmission and brake problems. Transmission ...</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>6</td>\n",
       "      <td>Other</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8474 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     DriveTrain  Mileage  SalePrice PriceCategory  \\\n",
       "0           FWD  53200.0    29000.0       Average   \n",
       "1           RWD  22690.0    55975.0     Expensive   \n",
       "2           FWD  17854.0    38900.0       Average   \n",
       "3           FWD  60907.0    22125.0         Cheap   \n",
       "4           FWD  41614.0    23946.0         Cheap   \n",
       "...         ...      ...        ...           ...   \n",
       "8469        FWD  78378.0    25500.0         Cheap   \n",
       "8470        AWD  30909.0    35590.0       Average   \n",
       "8471        FWD  30186.0    24000.0         Cheap   \n",
       "8472        FWD  22309.0    71077.0     Expensive   \n",
       "8473        FWD   9399.0    34988.0       Average   \n",
       "\n",
       "                                           CleanReviews    Year  newSize  \\\n",
       "0     Virtually nothing has gone wrong with my 2020 ...  2020.0      2.5   \n",
       "1     Stranded today. Could not get to work. Somethi...  2016.0      3.0   \n",
       "2     Excellent road car, quiet, stable, comfortable...  2020.0      3.5   \n",
       "3     PURCHASED FROM NYE TOYOTA, MY FIRST TACOMA. LO...  2021.0      2.5   \n",
       "4     I’ve own a 2020 Altima (under 30k miles) for a...  2020.0      2.4   \n",
       "...                                                 ...     ...      ...   \n",
       "8469  Only had the X5 for 4 weeks now but so far it ...  2022.0      3.6   \n",
       "8470  When I bought my 2020 Tacoma V6 (3.5L) 4x4 in ...  2019.0      3.6   \n",
       "8471  Everything is great except the rear view camer...  2015.0      2.5   \n",
       "8472  I have owned smaller SUV\\s and Trucks for over...  2020.0      5.7   \n",
       "8473  Transmission and brake problems. Transmission ...  2021.0      3.5   \n",
       "\n",
       "      newCyl     newMake   mpg  \n",
       "0          4      Toyota  27.0  \n",
       "1          6  Volkswagen  18.0  \n",
       "2          6       Other  18.0  \n",
       "3          4      Toyota  28.0  \n",
       "4          4      Nissan  24.0  \n",
       "...      ...         ...   ...  \n",
       "8469       6         BMW  18.0  \n",
       "8470       6      Toyota  18.0  \n",
       "8471       4    INFINITI  23.0  \n",
       "8472       8      Toyota  15.0  \n",
       "8473       6       Other  20.0  \n",
       "\n",
       "[8474 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Review column cleaning**\n",
    "- make a base model for nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data[['CleanReviews', 'PriceCategory']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CleanReviews</th>\n",
       "      <th>PriceCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Virtually nothing has gone wrong with my 2020 ...</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranded today. Could not get to work. Somethi...</td>\n",
       "      <td>Expensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Excellent road car, quiet, stable, comfortable...</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PURCHASED FROM NYE TOYOTA, MY FIRST TACOMA. LO...</td>\n",
       "      <td>Cheap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I’ve own a 2020 Altima (under 30k miles) for a...</td>\n",
       "      <td>Cheap</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        CleanReviews PriceCategory\n",
       "0  Virtually nothing has gone wrong with my 2020 ...       Average\n",
       "1  Stranded today. Could not get to work. Somethi...     Expensive\n",
       "2  Excellent road car, quiet, stable, comfortable...       Average\n",
       "3  PURCHASED FROM NYE TOYOTA, MY FIRST TACOMA. LO...         Cheap\n",
       "4  I’ve own a 2020 Altima (under 30k miles) for a...         Cheap"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_index = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hands down the best Jeep ever.. would take it over the Santa Fe any day of the week.. there’s no comparison.. performance is excellent.. have 70,000 miles on a 2018 and a 2019.. ac went out on one but warranty covered it🙂🙂, I absolutely love my jeep it’s comfortable reliable and completely rugged I never feel like I’m going to get stranded stuck or be taken down by anything you feel completely safe high up and well compact in this vehicle definitely worth the money I will never change my vehicle make!!! Jeep owner for GOOD!!! , have a 2019 high altitude , love this vehicle so comfortable and smooth love it, first vehicle i have loved driving. love the design and the smooth ride'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['CleanReviews'][rev_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing out the patter, make sure it's taking out the unwanted characters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'     ..            .. ’  ..   ..  70,000    2018   2019..         🙂🙂,      ’          ’                                  !!!    !!! ,   2019   ,         ,      .       '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(\"[a-zA-Z]+(?:'[a-z]+)?\", '', df['CleanReviews'][rev_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-proccessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- just lowercase all the reviews, the tfidvectorizer will take care of the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-f0607efd20df>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['CleanReviews'] = df['CleanReviews'].str.lower()\n"
     ]
    }
   ],
   "source": [
    "df['CleanReviews'] = df['CleanReviews'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CleanReviews</th>\n",
       "      <th>PriceCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>virtually nothing has gone wrong with my 2020 ...</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>stranded today. could not get to work. somethi...</td>\n",
       "      <td>Expensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>excellent road car, quiet, stable, comfortable...</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>purchased from nye toyota, my first tacoma. lo...</td>\n",
       "      <td>Cheap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i’ve own a 2020 altima (under 30k miles) for a...</td>\n",
       "      <td>Cheap</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        CleanReviews PriceCategory\n",
       "0  virtually nothing has gone wrong with my 2020 ...       Average\n",
       "1  stranded today. could not get to work. somethi...     Expensive\n",
       "2  excellent road car, quiet, stable, comfortable...       Average\n",
       "3  purchased from nye toyota, my first tacoma. lo...         Cheap\n",
       "4  i’ve own a 2020 altima (under 30k miles) for a...         Cheap"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- clean up reviews, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stopwords\n",
    "sw = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train, Test,  Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Creating a holdout set to use at the very end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['CleanReviews']\n",
    "y = data['PriceCategory']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t, X_hold, y_t, y_hold = train_test_split(X, y, test_size=0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_t, y_t, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatizing the text\n",
    "- try lemmantizing\n",
    "- try stemming\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/flatiron-school/BSC-DS-2022/blob/main/Phase4/CompleteNotebooks/06-NaturalLanguage-Modeling_complete.ipynb\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    '''\n",
    "    Translate nltk POS to wordnet tags\n",
    "    '''\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/flatiron-school/BSC-DS-2022/blob/main/Phase4/CompleteNotebooks/06-NaturalLanguage-Modeling_complete.ipynb\n",
    "def doc_preparer(doc, stop_words=sw):\n",
    "    '''\n",
    "    \n",
    "    :param doc: a document from the satire corpus \n",
    "    :return: a document string with words which have been \n",
    "            lemmatized, \n",
    "            parsed for stopwords, \n",
    "            made lowercase,\n",
    "            and stripped of punctuation and numbers.\n",
    "    '''\n",
    "    \n",
    "    regex_token = RegexpTokenizer(r\"([a-zA-Z]+(?:’[a-z]+)?)\")\n",
    "    doc = regex_token.tokenize(doc)\n",
    "    doc = [word.lower() for word in doc]\n",
    "    doc = [word for word in doc if word not in sw]\n",
    "#     print(doc)\n",
    "    doc = pos_tag(doc)\n",
    "    doc = [(word[0], get_wordnet_pos(word[1])) for word in doc]\n",
    "    lemmatizer = WordNetLemmatizer() \n",
    "    doc = [lemmatizer.lemmatize(word[0], word[1]) for word in doc]\n",
    "#     stemmer = nltk.stem.SnowballStemmer(language=\"english\") #trying out stemmer instead of lemmatizer\n",
    "#     doc = [stemmer.stem(word) for word in doc] #stemming words\n",
    "    return ' '.join(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_docs = [doc_preparer(doc, sw) for doc in X_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The ride is great, Toyota gives comfort and space, very good on gas and good price to own the car all you need is on this vehicle, This car rides nice and runs great it meets all of my driving needs. Would definitely buy another one. I needed a reliable car to get to work. Thank you, I went with the 2017 model due to the new 2018 + models having issues w/ that new 8 speed transmission. This was the last model w/  a bulletproof transmission so far. I hope to pay this car off and be payment free and problem free for the next decade. Always go with Toyota. They are the most reliable by statistics and no one wants to have car troubles.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.iloc[rev_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ride great toyota give comfort space good gas good price car need vehicle car ride nice run great meet drive need would definitely buy another one need reliable car get work thank go model due new model issue w new speed transmission last model w bulletproof transmission far hope pay car payment free problem free next decade always go toyota reliable statistic one want car trouble'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_docs[rev_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    token_pattern=r\"([a-zA-Z]+(?:'[a-z]+)?)\",\n",
    "    stop_words=sw,\n",
    "#     max_df=.95,  # removes words that appear in more than 95% of docs\n",
    "#     min_df=2     # removes words that appear 2 or fewer times\n",
    ")\n",
    "\n",
    "#vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.fit(X_train)\n",
    "\n",
    "X_train_vec = vectorizer.transform(X_train)\n",
    "X_val_vec = vectorizer.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4869732470711663"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train_vec, y_train)\n",
    "classifier.score(X_train_vec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41321447299423175"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(X_val_vec, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemmentizer with tfid vectorizer (hyper param of max_df and min_df) 0.41006816990036704\n",
      "lemmentizer with tfid vectorizer 0.41321447299423175\n",
      "stemmer with tfid vectorizer 0.41321447299423175\n",
      "stemming with count vectorizer 0.36392239119035136\n"
     ]
    }
   ],
   "source": [
    "print('lemmentizer with tfid vectorizer (hyper param of max_df and min_df) 0.41006816990036704')\n",
    "print('lemmentizer with tfid vectorizer 0.41321447299423175') #best accuracy\n",
    "print('stemmer with tfid vectorizer 0.41321447299423175')\n",
    "print('stemming with count vectorizer 0.36392239119035136')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- stemming and lemmatizing text did not help\n",
    "- probably because there is not enough variety in the reviews to make a difference\n",
    "- just using a 'vanilla' tfid vectorizer was the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
